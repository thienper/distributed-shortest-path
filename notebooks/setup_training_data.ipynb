{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9426c75c",
   "metadata": {},
   "source": [
    "# Setup Training Data for 10-Minute GraphSAGE Training\n",
    "\n",
    "H∆∞·ªõng d·∫´n t·∫°o d·ªØ li·ªáu l·ªõn h∆°n ƒë·ªÉ train model trong ~10 ph√∫t.\n",
    "\n",
    "**C·∫•u tr√∫c d·ªØ li·ªáu m·ª•c ti√™u:**\n",
    "- 2000 samples training (thay v√¨ 240)\n",
    "- Validate/test proportional\n",
    "- K√©o d√†i training ~10 ph√∫t v·ªõi GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b362c957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Th√™m project path\n",
    "project_root = Path('../').resolve()\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "print(f\"‚úì Project root: {project_root}\")\n",
    "print(f\"‚úì Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07db5335",
   "metadata": {},
   "source": [
    "## 1. Define Project Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2d2429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ƒê·ªãnh nghƒ©a c·∫•u tr√∫c th∆∞ m·ª•c\n",
    "DATA_DIR = project_root / 'data' / 'graph_medium'\n",
    "MODELS_DIR = project_root / 'models'\n",
    "LOGS_DIR = project_root / 'logs'\n",
    "\n",
    "# T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥\n",
    "for dir_path in [DATA_DIR, MODELS_DIR, LOGS_DIR]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    print(f\"‚úì Created/verified: {dir_path}\")\n",
    "\n",
    "print(\"\\nüìÅ Project Structure:\")\n",
    "print(f\"   DATA_DIR   = {DATA_DIR}\")\n",
    "print(f\"   MODELS_DIR = {MODELS_DIR}\")\n",
    "print(f\"   LOGS_DIR   = {LOGS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd01c5e",
   "metadata": {},
   "source": [
    "## 2. Load Graph Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8a6987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ki·ªÉm tra v√† load d·ªØ li·ªáu graph\n",
    "nodes_file = DATA_DIR / 'graph_nodes.csv'\n",
    "edges_file = DATA_DIR / 'graph_edges.csv'\n",
    "\n",
    "if not nodes_file.exists():\n",
    "    print(f\"‚ö†Ô∏è  {nodes_file} kh√¥ng t·ªìn t·∫°i. T√¥i s·∫Ω sinh d·ªØ li·ªáu graph...\")\n",
    "    # Sinh graph m·ªõi n·∫øu ch∆∞a c√≥\n",
    "    import subprocess\n",
    "    result = subprocess.run([sys.executable, str(project_root / 'src' / 'data' / 'generate_graph.py')],\n",
    "                          capture_output=True, text=True)\n",
    "    print(result.stdout)\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error: {result.stderr}\")\n",
    "\n",
    "# Load d·ªØ li·ªáu\n",
    "nodes_df = pd.read_csv(nodes_file)\n",
    "edges_df = pd.read_csv(edges_file)\n",
    "\n",
    "print(f\"\\nüìä Graph Statistics:\")\n",
    "print(f\"   Nodes: {len(nodes_df)}\")\n",
    "print(f\"   Edges: {len(edges_df)}\")\n",
    "print(f\"\\n   Nodes sample:\\n{nodes_df.head()}\")\n",
    "print(f\"\\n   Edges sample:\\n{edges_df.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b18a4e0",
   "metadata": {},
   "source": [
    "## 3. Build NetworkX Graph & Generate Path Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e4371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build NetworkX graph ƒë·ªÉ t√≠nh shortest path nhanh\n",
    "print(\"üî® Building NetworkX graph...\")\n",
    "G = nx.Graph()\n",
    "num_nodes = len(nodes_df)\n",
    "G.add_nodes_from(range(num_nodes))\n",
    "\n",
    "for _, row in edges_df.iterrows():\n",
    "    src, dst, weight = int(row['source']), int(row['target']), float(row['weight'])\n",
    "    if src < num_nodes and dst < num_nodes:\n",
    "        G.add_edge(src, dst, weight=weight)\n",
    "\n",
    "print(f\"   ‚úì Graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "\n",
    "# Sinh d·ªØ li·ªáu training samples\n",
    "print(\"\\nüéØ Generating 2000 path samples for 10-minute training...\")\n",
    "NUM_SAMPLES = 2000\n",
    "np.random.seed(42)\n",
    "\n",
    "sources = []\n",
    "targets = []\n",
    "costs = []\n",
    "\n",
    "# Random select source-target pairs\n",
    "for i in tqdm(range(NUM_SAMPLES), desc=\"Generating paths\"):\n",
    "    src = np.random.randint(0, num_nodes)\n",
    "    dst = np.random.randint(0, num_nodes)\n",
    "    \n",
    "    if src == dst:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # D√πng NetworkX ƒë·ªÉ t√≠nh chi ph√≠ Dijkstra nhanh\n",
    "        cost = nx.shortest_path_length(G, source=src, target=dst, weight='weight')\n",
    "        sources.append(src)\n",
    "        targets.append(dst)\n",
    "        costs.append(cost)\n",
    "    except nx.NetworkXNoPath:\n",
    "        continue\n",
    "\n",
    "# ƒê·∫£m b·∫£o c√≥ ƒë·ªß samples\n",
    "sources = sources[:NUM_SAMPLES]\n",
    "targets = targets[:NUM_SAMPLES]\n",
    "costs = costs[:NUM_SAMPLES]\n",
    "\n",
    "print(f\"   ‚úì Generated {len(sources)} valid paths\")\n",
    "print(f\"   Cost statistics: min={min(costs):.2f}, max={max(costs):.2f}, mean={np.mean(costs):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339e6aef",
   "metadata": {},
   "source": [
    "## 4. Split Data into Train/Val/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1daa8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o DataFrame\n",
    "paths_df = pd.DataFrame({\n",
    "    'source': sources,\n",
    "    'target': targets,\n",
    "    'cost': costs\n",
    "})\n",
    "\n",
    "# Split: Train 80% (1600), Val 10% (200), Test 10% (200)\n",
    "n_total = len(paths_df)\n",
    "n_train = int(0.8 * n_total)\n",
    "n_val = int(0.1 * n_total)\n",
    "\n",
    "train_df = paths_df[:n_train]\n",
    "val_df = paths_df[n_train:n_train + n_val]\n",
    "test_df = paths_df[n_train + n_val:]\n",
    "\n",
    "# L∆∞u CSV\n",
    "train_file = DATA_DIR / 'paths_train.csv'\n",
    "val_file = DATA_DIR / 'paths_val.csv'\n",
    "test_file = DATA_DIR / 'paths_test.csv'\n",
    "\n",
    "train_df.to_csv(train_file, index=False)\n",
    "val_df.to_csv(val_file, index=False)\n",
    "test_df.to_csv(test_file, index=False)\n",
    "\n",
    "print(f\"üíæ Dataset Split:\")\n",
    "print(f\"   Training:   {len(train_df):4d} samples ‚Üí {train_file}\")\n",
    "print(f\"   Validation: {len(val_df):4d} samples ‚Üí {val_file}\")\n",
    "print(f\"   Test:       {len(test_df):4d} samples ‚Üí {test_file}\")\n",
    "print(f\"   Total:      {n_total:4d} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe902ac",
   "metadata": {},
   "source": [
    "## 5. Setup Training Configuration for 10-Minute Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29260d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C·∫•u h√¨nh training ƒë·ªÉ ch·∫°y ~10 ph√∫t\n",
    "config = {\n",
    "    \"model\": {\n",
    "        \"hidden_dim\": 64,\n",
    "        \"num_layers\": 2,\n",
    "        \"dropout\": 0.3,\n",
    "        \"aggregator\": \"mean\"\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"num_epochs\": 100,           # 10 ph√∫t / 100 epochs ‚âà 6 gi√¢y/epoch\n",
    "        \"batch_size\": 32,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"weight_decay\": 1e-5,\n",
    "        \"optimizer\": \"adam\"\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"num_train_samples\": len(train_df),\n",
    "        \"num_val_samples\": len(val_df),\n",
    "        \"num_test_samples\": len(test_df),\n",
    "        \"num_nodes\": num_nodes,\n",
    "        \"num_edges\": G.number_of_edges()\n",
    "    },\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "\n",
    "# L∆∞u config\n",
    "config_file = MODELS_DIR / 'config.json'\n",
    "with open(config_file, 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(\"‚öôÔ∏è  Training Configuration:\")\n",
    "print(f\"   Device: {config['device']}\")\n",
    "print(f\"   Epochs: {config['training']['num_epochs']}\")\n",
    "print(f\"   Batch size: {config['training']['batch_size']}\")\n",
    "print(f\"   Learning rate: {config['training']['learning_rate']}\")\n",
    "print(f\"   Estimated time: ~10 minutes\")\n",
    "print(f\"\\n   Config saved ‚Üí {config_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507ecb19",
   "metadata": {},
   "source": [
    "## 6. Project Structure Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549adeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def print_tree(directory, prefix=\"\", max_depth=3, current_depth=0):\n",
    "    \"\"\"In c·∫•u tr√∫c th∆∞ m·ª•c\"\"\"\n",
    "    if current_depth >= max_depth:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        items = sorted(os.listdir(directory))\n",
    "        items = [i for i in items if not i.startswith('.')]\n",
    "        \n",
    "        for i, item in enumerate(items):\n",
    "            path = os.path.join(directory, item)\n",
    "            is_last = i == len(items) - 1\n",
    "            current_prefix = \"‚îî‚îÄ‚îÄ \" if is_last else \"‚îú‚îÄ‚îÄ \"\n",
    "            print(f\"{prefix}{current_prefix}{item}\")\n",
    "            \n",
    "            if os.path.isdir(path) and item not in ['.venv', '__pycache__', '.git']:\n",
    "                extension = \"    \" if is_last else \"‚îÇ   \"\n",
    "                print_tree(path, prefix + extension, max_depth, current_depth + 1)\n",
    "    except PermissionError:\n",
    "        pass\n",
    "\n",
    "print(\"üìÅ Project Structure Ready for Training:\\n\")\n",
    "print_tree(str(project_root))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe38dde",
   "metadata": {},
   "source": [
    "## 7. Next Steps - Start Training\n",
    "\n",
    "Ch·∫°y l·ªánh sau ƒë·ªÉ b·∫Øt ƒë·∫ßu training trong 10 ph√∫t:\n",
    "\n",
    "```bash\n",
    "# T·ª´ th∆∞ m·ª•c project root\n",
    "python train_model.py --data-dir data/graph_medium --models-dir models --num-epochs 100 --batch-size 32\n",
    "\n",
    "# Ho·∫∑c d√πng script\n",
    "./train.sh  # Tr√™n Linux/Mac\n",
    "train.bat   # Tr√™n Windows\n",
    "```\n",
    "\n",
    "**C√°c file s·∫Ω ƒë∆∞·ª£c sinh ra:**\n",
    "- `models/best_model.pt` - Tr·ªçng s·ªë model (t·ª± ƒë·ªông l∆∞u t·ªët nh·∫•t)\n",
    "- `models/config.json` - C·∫•u h√¨nh training\n",
    "- `models/results.json` - K·∫øt qu·∫£ (loss, metrics)\n",
    "- `logs/training_*.log` - Chi ti·∫øt training"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
